{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook para demostrar pipeline que utiliza el modelo de regresion logistica Lasso para distinguir entre AI o no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cargar librerias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\angel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\angel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Save the model with pkl\n",
    "import pickle\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import ripser\n",
    "from persim import plot_diagrams, PersistenceImager\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar modelo y pipeline completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda\\envs\\gcwtdaENV\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 10 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "with open('log_reg_model.pkl', 'rb') as f:\n",
    "    model_LR = pickle.load(f)\n",
    "\n",
    "# Load the keras model\n",
    "from keras.models import load_model\n",
    "model_lstm = load_model('lstm_model.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe Model...\n",
      "Done. 855380 words loaded!\n"
     ]
    }
   ],
   "source": [
    "def load_glove_model(glove_file):\n",
    "    print(\"Loading GloVe Model...\")\n",
    "    glove_model = {}\n",
    "    with open(glove_file, 'r', encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            embedding = np.array([float(val) for val in split_line[1:]])\n",
    "            glove_model[word] = embedding\n",
    "    print(\"Done.\", len(glove_model), \"words loaded!\")\n",
    "    return glove_model\n",
    "\n",
    "glove_file = 'glove_6B/glove-sbwc.i25.vec'\n",
    "glove_model = load_glove_model(glove_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para hacer pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prueba(ejemplo):\n",
    "    print(\"Ejemplo:\", ejemplo)\n",
    "\n",
    "    \n",
    "    sentences = sent_tokenize(ejemplo)\n",
    "\n",
    "\n",
    "    tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "\n",
    "    def sentence_embedding(sentence_tokens, embeddings, stop_words):\n",
    "        embedding_dim = 300  # GloVe 50d\n",
    "        sentence_vector = np.zeros(embedding_dim)\n",
    "        word_count = 0\n",
    "        \n",
    "        for word in sentence_tokens:\n",
    "            word = word.lower()\n",
    "            if word not in stop_words and word in embeddings:\n",
    "                sentence_vector += embeddings[word]\n",
    "                word_count += 1\n",
    "                \n",
    "        if word_count > 0:\n",
    "            sentence_vector /= word_count  # Optionally, normalize by number of words\n",
    "        \n",
    "        return sentence_vector\n",
    "\n",
    "    embeddings = [sentence_embedding(sentence, glove_model, stopwords.words('spanish')) for sentence in tokenized_sentences]\n",
    "    embeddings = np.array(embeddings)\n",
    "\n",
    "\n",
    "    ripserperiod = ripser.ripser(embeddings)[\"dgms\"]\n",
    "    h0_diagram = ripserperiod[0].copy()\n",
    "    h0_diagram = h0_diagram[np.isfinite(h0_diagram).all(axis=1)]\n",
    "    # Generate the images for all the persistence diagrams at once to assure the same pixel size\n",
    "    # Manually set birth and persistence ranges based on your data\n",
    "\n",
    "    #Los siguientes parámetros mantienen el tamaño de la imagen de persistencia (matriz)\n",
    "    birth_range = (0, 0.5)  \n",
    "    pers_range = (0, 3)   \n",
    "\n",
    "    # Initialize PersistenceImager\n",
    "    pimgr = PersistenceImager(pixel_size=0.01, birth_range=birth_range, pers_range=pers_range)\n",
    "    #pimgr = PersistenceImager(pixel_size=0.1)\n",
    "    pimgr.kernel_params = {'sigma': 0.01}\n",
    "    pdgms = h0_diagram#lista_vectores\n",
    "    #pimgr.fit(lista_vectores, skew=True)\n",
    "    pimgs = pimgr.transform(pdgms,skew=True)\n",
    "\n",
    "    '''\n",
    "    pimgr.plot_image(pimgs)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    '''\n",
    "    #predicción LASSO\n",
    "    #flatten the image to a 1D array\n",
    "    pimgs = pimgs.flatten()\n",
    "    pred1 = model_LR.predict_proba(pimgs.reshape(1,-1))\n",
    "    print(\"Predicción TDA: Humano = \", pred1[0][0]*100, \"%   , AI = \", pred1[0][1]*100, \"%\")\n",
    "\n",
    "    #predicción LSTM\n",
    "    max_timesteps = 8\n",
    "    reshaped_data = embeddings.reshape((1, embeddings.shape[0], 300))\n",
    "    X_padded = pad_sequences(reshaped_data, maxlen=max_timesteps, dtype='float32', padding='post', truncating='post')\n",
    "    pred2 = model_lstm.predict(X_padded, verbose=0)\n",
    "    print(\"Predicción LSTM: Humano = \", (1-pred2[0][0])*100, \"%   , AI = \", pred2[0][0]*100, \"%\")\n",
    "\n",
    "    #prediccion final\n",
    "    w=4\n",
    "    pred_final=((pred1[0][1]+pred2[0][0]*w)/(1+w))\n",
    "    print(\"Predicción final: Humano = \", (1-pred_final)*100, \"%   , AI = \", pred_final*100, \"%\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aquí se pueden realizar pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo: Un buen profesor. es alguien que se preocupa por sus estudiantes. Se encarga de hacer que los alumnos se cuestionen acerca de lo que creen que saben\n",
      "Predicción TDA: Humano =  60.62863775273956 %   , AI =  39.37136224726044 %\n",
      "Predicción LSTM: Humano =  83.85356515645981 %   , AI =  16.14643484354019 %\n",
      "Predicción final: Humano =  79.20857967571575 %   , AI =  20.791420324284243 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda\\envs\\gcwtdaENV\\lib\\site-packages\\ripser\\ripser.py:253: UserWarning: The input point cloud has more columns than rows; did you mean to transpose?\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "caso='Un buen profesor. es alguien que se preocupa por sus estudiantes. Se encarga de hacer que los alumnos se cuestionen acerca de lo que creen que saben'\n",
    "prueba(caso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo: Un buen profesor necesita pasión por enseñar, dominio de su materia y habilidades de comunicación que le permitan explicar conceptos de forma clara y accesible. Además, debe ser paciente y empático, comprendiendo que cada estudiante aprende a su propio ritmo. Su capacidad para motivar es clave, inspirando curiosidad y ganas de aprender en sus alumnos. También debe ser flexible y creativo, adaptando sus estrategias según las necesidades del grupo, y practicar la escucha activa para atender dudas y preocupaciones. La evaluación y la retroalimentación efectiva son esenciales para detectar fortalezas y áreas de mejora, ofreciendo sugerencias útiles. Un buen profesor utiliza recursos variados, como herramientas tecnológicas y actividades interactivas, para enriquecer el aprendizaje. Por último, su compromiso con la formación continua le permite mejorar constantemente su metodología y mantenerse actualizado en su disciplina.\n",
      "Predicción TDA: Humano =  9.86844183525023 %   , AI =  90.13155816474978 %\n",
      "Predicción LSTM: Humano =  0.05404949188232422 %   , AI =  99.94595050811768 %\n",
      "Predicción final: Humano =  2.016927960555903 %   , AI =  97.9830720394441 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda\\envs\\gcwtdaENV\\lib\\site-packages\\ripser\\ripser.py:253: UserWarning: The input point cloud has more columns than rows; did you mean to transpose?\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "caso='Un buen profesor necesita pasión por enseñar, dominio de su materia y habilidades de comunicación que le permitan explicar conceptos de forma clara y accesible. Además, debe ser paciente y empático, comprendiendo que cada estudiante aprende a su propio ritmo. Su capacidad para motivar es clave, inspirando curiosidad y ganas de aprender en sus alumnos. También debe ser flexible y creativo, adaptando sus estrategias según las necesidades del grupo, y practicar la escucha activa para atender dudas y preocupaciones. La evaluación y la retroalimentación efectiva son esenciales para detectar fortalezas y áreas de mejora, ofreciendo sugerencias útiles. Un buen profesor utiliza recursos variados, como herramientas tecnológicas y actividades interactivas, para enriquecer el aprendizaje. Por último, su compromiso con la formación continua le permite mejorar constantemente su metodología y mantenerse actualizado en su disciplina.'\n",
    "prueba(caso)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcwtdaENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
